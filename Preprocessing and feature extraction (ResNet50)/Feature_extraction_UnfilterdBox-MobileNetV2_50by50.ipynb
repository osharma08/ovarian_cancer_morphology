{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optional-little",
   "metadata": {},
   "source": [
    "# 1. Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virgin-stress",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 17:34:18.481096: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-23 17:34:19.451280: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "from PIL import Image\n",
    "from skimage import measure\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "from skimage.measure import label, regionprops, regionprops_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32114e",
   "metadata": {},
   "source": [
    "# 2. MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9d34af",
   "metadata": {},
   "source": [
    "## 2.1 Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indirect-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2275242/838670082.py:11: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  model = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(50, 50, 3))\n",
      "2024-11-23 17:34:21.097963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9612 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, GlobalAveragePooling2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    #load pre-trained model\n",
    "    model = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(50, 50, 3))\n",
    "    #feature extraction from pre-trained model\n",
    "    layer = model.get_layer(name=\"block_16_project\").output #512 features\n",
    "    output = GlobalAveragePooling2D()(layer)\n",
    "    # define new model\n",
    "    feature_extraction_model = Model(inputs=model.inputs, outputs=output)\n",
    "    # summarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ddb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the file paths for the images and corresponding masks\n",
    "image_path = '/4tbint/Corrected Merged FOVs/Set5/20200408_N7863__2020-04-08T10_57_43-Measurement 2'\n",
    "mask_path = '/4tbint/Cellpose Masks/Set5/20200408_N7863__2020-04-08T10_57_43-Measurement 2'\n",
    "\n",
    "#use the glob library to generate lists of image and mask filenames\n",
    "images =  sorted([os.path.basename(x) for x in glob.glob(image_path + '/*.tiff')])\n",
    "cellpose_mask = sorted([os.path.basename(x) for x in glob.glob(mask_path + '/*.tiff')])\n",
    "\n",
    "ch1 = [] #fibroblast\n",
    "ch2 = [] #cancer\n",
    "ch4 = [] #dapi\n",
    "\n",
    "\n",
    "for i in range(0, 1152, 3):\n",
    "    \n",
    "    CH1_path = os.path.join(image_path, images[i])\n",
    "    CH2_path = os.path.join(image_path, images[i+2]) #for MHB ch3 is cancer \n",
    "    CH4_path = os.path.join(image_path, images[i+1]) #for MHB ch2 is DAPI\n",
    "\n",
    " \n",
    "    #read images and masks using the Image library, and converts them to numpy arrays.\n",
    "    ch1_img = Image.open(CH1_path)\n",
    "    ch2_img = Image.open(CH2_path)\n",
    "    ch4_img = Image.open(CH4_path)\n",
    "\n",
    "    ch1.append(np.array(ch1_img))\n",
    "    ch2.append(np.array(ch2_img))\n",
    "    ch4.append(np.array(ch4_img))\n",
    "\n",
    "ch1_max = np.max(ch1)\n",
    "ch2_max = np.max(ch2)\n",
    "ch4_max = np.max(ch4)\n",
    "print(\"Maximum intensity for channel 1:\", ch1_max)\n",
    "print(\"Maximum intensity for channel 2:\", ch2_max)\n",
    "print(\"Maximum intensity for channel 4:\", ch4_max)\n",
    "\n",
    "ch1_q099 =  np.quantile(ch1, 0.99)\n",
    "ch2_q099 =  np.quantile(ch2, 0.99)\n",
    "ch4_q099 =  np.quantile(ch4, 0.99)\n",
    "print(\"Quantile_099 channel 1:\", ch1_q099)\n",
    "print(\"Quantile_099 channel 2:\", ch2_q099)\n",
    "print(\"Quantile_099 channel 4:\", ch4_q099)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-trigger",
   "metadata": {},
   "source": [
    "## 2.3 Read images as tensors and extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94d5c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example of preprocessing and extracting features\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.resize(image, (50, 50))  # Resize to match model input\n",
    "    image = preprocess_input(image)  # Apply MobileNetV2-specific preprocessing\n",
    "    return image\n",
    "\n",
    "#define the file paths for the images and corresponding masks\n",
    "image_path = '/4tbint/Corrected Merged FOVs/Set5/20200408_N7863__2020-04-08T10_57_43-Measurement 2'\n",
    "mask_path = '/4tbint/Cellpose Masks/Set5/20200408_N7863__2020-04-08T10_57_43-Measurement 2'\n",
    "\n",
    "#use the glob library to generate lists of image and mask filenames\n",
    "images =  sorted([os.path.basename(x) for x in glob.glob(image_path + '/*.tiff')])\n",
    "cellpose_mask = sorted([os.path.basename(x) for x in glob.glob(mask_path + '/*.tiff')])\n",
    "\n",
    "# \"mean_feature_list\" and \"j\" variables are initialized to empty list and 0, respectively to store the features for each image and to iterate over the list of masks.\n",
    "mean_fetaure_list =[]\n",
    "image_list = []\n",
    "j=0\n",
    "\n",
    "#loop with step size of 3 to iterate over a range of indices, pulling the filenames for three channels of each image.\n",
    "for i in range(0, 1152, 3):\n",
    "    \n",
    "    CH1_path = os.path.join(image_path, images[i])\n",
    "    CH2_path = os.path.join(image_path, images[i+2]) #for MHB ch3 is cancer \n",
    "    CH4_path = os.path.join(image_path, images[i+1]) #for MHB ch2 is DAPI \n",
    "    \n",
    "    #read images and masks using the Image library, and converts them to numpy arrays.\n",
    "    ch1_img = Image.open(CH1_path)\n",
    "    ch2_img = Image.open(CH2_path)\n",
    "    ch4_img = Image.open(CH4_path)\n",
    "\n",
    "    ch1_img_arr = np.array(ch1_img)\n",
    "    ch2_img_arr = np.array(ch2_img)\n",
    "    ch4_img_arr = np.array(ch4_img)\n",
    "    \n",
    "\n",
    "    #use cellpose mask to extract individual cell regions,to generate 50x50 pixel images.\n",
    "    cellpose_path = os.path.join(mask_path, cellpose_mask[j])\n",
    "\n",
    "    cellpose_img = Image.open(cellpose_path)\n",
    "    cellpose_img_array = np.array(cellpose_img)\n",
    "    labels = label(cellpose_img_array)\n",
    "    regions = measure.regionprops(labels)\n",
    "\n",
    "    j=j+1\n",
    "    single_cell_bbox = []\n",
    "\n",
    "    for props in regions:\n",
    "        y0, x0 = props.centroid\n",
    "        y = int(round(y0))\n",
    "        x = int(round(x0))\n",
    "        box_ch1 = ch1_img_arr[x-25:x+25,y-25:y+25]\n",
    "        box_ch2 = ch2_img_arr[x-25:x+25,y-25:y+25]\n",
    "        box_ch4 = ch4_img_arr[x-25:x+25,y-25:y+25]\n",
    "\n",
    "        if (box_ch1.shape == (50,50)):\n",
    "            coordinate = x, y\n",
    "            \n",
    "            box_ch1 = (box_ch1.astype('float32')/ch1_q099)*255\n",
    "            box_ch2 = (box_ch2.astype('float32')/ch2_q099)*255\n",
    "            box_ch4 = (box_ch4.astype('float32')/ch4_q099)*255\n",
    "            \n",
    "            singlecell = np.stack((box_ch1, box_ch2, box_ch4), axis=-1)\n",
    "            reshaped_singlecell = singlecell.reshape((1,50,50,3))\n",
    "            single_cell_bbox.append(reshaped_singlecell)\n",
    "\n",
    "    single_cells = np.array(single_cell_bbox)\n",
    "\n",
    "    if len(single_cells) != 0:\n",
    "        \n",
    "        print(images[i])\n",
    "    \n",
    "        #convert single cell objects into a tensor using tf.data.Dataset.from_tensor_slices.\n",
    "        single_cell_tensor = tf.data.Dataset.from_tensor_slices(single_cells)\n",
    "\n",
    "        def extract_features(image):\n",
    "            preprocessed_image = preprocess_image(image)\n",
    "            features = feature_extraction_model(preprocessed_image)\n",
    "            return features\n",
    "\n",
    "        #A map operation is used to apply a feature extraction function, extract_features, to each cell image \n",
    "        #using a pre-trained model. This creates a feature_dataset of extracted features.\n",
    "        feature_dataset = single_cell_tensor.map(extract_features)\n",
    "\n",
    "        #features are summed across all cells, divided by the number of cells, and added to the mean_feature_list.\n",
    "        sum_feature_dataset = tf.zeros((1,320))\n",
    "\n",
    "        for f in feature_dataset:\n",
    "            sum_feature_dataset += f\n",
    "\n",
    "        mean_feature = sum_feature_dataset/len(feature_dataset)\n",
    "\n",
    "        mean_fetaure_list.append(mean_feature)\n",
    "        image_list.append(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert mean feature tensor array to numpy array\n",
    "feature_list = [tensor.numpy() for tensor in mean_fetaure_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7496e186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382\n"
     ]
    }
   ],
   "source": [
    "len(feature_list)\n",
    "print(len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e110030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a 2D numpy array from the feature list\n",
    "feature_array = np.vstack(feature_list)\n",
    "\n",
    "# Create a DataFrame with column names\n",
    "df = pd.DataFrame(feature_array, columns=['feature{}'.format(i+1) for i in range(320)])\n",
    "\n",
    "#add col to the beginning of the dataframe\n",
    "df.insert(0, 'Image', image_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255caf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe as excel \n",
    "df.to_excel(\"/home/gauss/Desktop/Revised_Data_Features/Pretrained baseline MobileNetV2 Bbox Size 50/MHB/Plate_7.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe746488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e73900e-aa15-4186-9b30-e6efc71ec24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
