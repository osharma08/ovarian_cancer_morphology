{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caring-drinking",
   "metadata": {},
   "source": [
    "# Step 1:\n",
    "\n",
    "## Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "banned-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from pandas import read_excel\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-helen",
   "metadata": {},
   "source": [
    "# Step 2: Computing the statistics for DMSO wells\n",
    "## a) Read the dataframe with mean aggregated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae6e52c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plate_1\n",
      "Plate_1_annot.xlsx\n",
      "Plate_2\n",
      "Plate_2_annot.xlsx\n",
      "Plate_3\n",
      "Plate_3_annot.xlsx\n",
      "Plate_4\n",
      "Plate_4_annot.xlsx\n",
      "Plate_5\n",
      "Plate_5_annot.xlsx\n",
      "Plate_6\n",
      "Plate_6_annot.xlsx\n",
      "Plate_7\n",
      "Plate_7_annot.xlsx\n",
      "Plate_8\n",
      "Plate_8_annot.xlsx\n"
     ]
    }
   ],
   "source": [
    "feature_folder = '/home/gauss/Desktop/Trained Features_FilteredBBox_pooledwellsd2d3d4/O8W/'\n",
    "annot_folder = '/4tbint/Plate_annotations_newMoAs/'\n",
    "\n",
    "for filename in sorted(os.listdir(feature_folder)):\n",
    "    plate_path = os.path.join(feature_folder, filename)\n",
    "    #print(plate_path)\n",
    "    file = filename.split(\".\")[0]\n",
    "    print(file)\n",
    "    feature_data = pd.read_excel(plate_path)\n",
    "    prefix = file.split(\".\")[0]\n",
    "    #print(prefix)\n",
    "\n",
    "    for annot_file in sorted(os.listdir(annot_folder)):\n",
    "        ann_file = annot_file.split(\".\")\n",
    "        ann_file = annot_file.split(\"_annot\")[0]\n",
    "        #print(ann_file)\n",
    "        annot_path = os.path.join(annot_folder, annot_file)\n",
    "        #print(annot_path)\n",
    "        if file == ann_file:\n",
    "            print(annot_file)\n",
    "\n",
    "            annot_data = pd.read_excel(annot_path)\n",
    "                \n",
    "            feature_data = feature_data.join(annot_data, lsuffix='_left', rsuffix='_right')\n",
    "            #Put values as \"dmso\" as we are only interested in rows with Label as \"dmso\"\n",
    "            values =['DMSO'] \n",
    "            #Search for rows where column Label is in Values\n",
    "            data_dmso = feature_data[feature_data.Label.isin(values) == True]\n",
    "            #Select all rows and all columns from those in the \"values\" variable \n",
    "            data_dmso = data_dmso.loc[:,:]\n",
    "\n",
    "            data_dmso = data_dmso.reset_index()\n",
    "\n",
    "            #For CP dataset\n",
    "            #data_dmso = data_dmso.drop(['index','FileName_Cancer','FileName_Cellpose','FileName_Dapi','FileName_Fibroblast','ImageNumber','Well_number','Compound', 'MoA', 'Concentration', 'Label', 'Category'], axis=1) \n",
    "            # For TL dataset ---> \n",
    "            data_dmso = data_dmso.drop(['Unnamed: 0','index', 'Image', 'Well_number','Compound', 'MoA', 'Concentration', 'Label', 'Category'], axis=1)\n",
    "       \n",
    "\n",
    "            #create new dataframe with the same column names as \"data_dmso\" to have feature cols\n",
    "            stats_dmso = pd.DataFrame(columns=data_dmso.columns)\n",
    "\n",
    "            #Compute median and median absolute deviation along the feature columns\n",
    "            data_dmso_median = data_dmso.median()\n",
    "            data_dmso_mad = data_dmso[data_dmso.columns[0:(len(data_dmso.columns))]].apply(stats.median_abs_deviation)\n",
    "\n",
    "            #Append the list of median and median absolute deviation to the dataframe \"stats_dmso\"\n",
    "            stats_dmso = stats_dmso.append(pd.Series(data_dmso_median.tolist(), index=stats_dmso.columns), ignore_index=True)\n",
    "            stats_dmso = stats_dmso.append(pd.Series(data_dmso_mad.tolist(), index=stats_dmso.columns), ignore_index=True)\n",
    "\n",
    "            #Add the column \"Statistics\" in the stats_dmso dataframe\n",
    "            stats_dmso.insert(0, \"Statistics\", ['Median', 'Median absolute deviation'], True)\n",
    "\n",
    "\n",
    "            #Take only feature columns from the median aggregated well dataframe (basically originally dataframe that we read in the beginning)\n",
    "\n",
    "            #For CP Dataset\n",
    "            #data_features = feature_data.iloc[0:384,5:713] \n",
    "\n",
    "            #For TL dataset\n",
    "            data_features = feature_data.iloc[0:384,2:514] \n",
    "\n",
    "            #Subtract the median row from 'stats_dmso' to the original data\n",
    "            features_sub_median = data_features.subtract(stats_dmso.iloc[0,1:], axis = 1) \n",
    "            #for TL: stats_dmso.iloc[0,1:]\n",
    "            #For CP: dataset stats_dmso.iloc[0,1:709]\n",
    "\n",
    "            #Divide the median subtracted dataframe from dmso MAD row in the 'stats_dmso' dataframe\n",
    "            features_divide_mad = features_sub_median.div(stats_dmso.iloc[1,1:], axis = 1) \n",
    "            #for TL: stats_dmso.iloc[1,1:]\n",
    "            #For CP: dataset stats_dmso.iloc[1,1:709]\n",
    "\n",
    "            #Add the Label column annotation to the dataframe print it and save it as excel file\n",
    "            normalized_data = features_divide_mad.join(feature_data['Label'])\n",
    "\n",
    "            normalized_data = normalized_data.iloc[:,0:len(normalized_data.columns)-1].join(annot_data, lsuffix='_left', rsuffix='_right')\n",
    "\n",
    "            normalized_data_filtered = normalized_data[normalized_data.columns.drop(list(normalized_data.filter(regex='_X')))]\n",
    "            normalized_data_filtered = normalized_data_filtered[normalized_data_filtered.columns.drop(list(normalized_data_filtered.filter(regex='_Y')))]\n",
    "            #normalized_data_filtered = normalized_data_filtered.drop(['index'])\n",
    "\n",
    "    #Save the final dataframe with median aggregated and normalized features at well-level for analysis\n",
    "    normalized_data_filtered.to_excel(\"/home/gauss/Desktop/Trained Features_FilteredBBox_pooledwellsd2d3d4/O8W_normalized/{}.xlsx\".format(prefix))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8011d5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gauss/Desktop/Trained Features_FilteredBBox_pooledwellsd2d3d4/O8W_normalized\n"
     ]
    }
   ],
   "source": [
    "cd /home/gauss/Desktop/Trained Features_FilteredBBox_pooledwellsd2d3d4/O8W_normalized/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1261c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r .ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-fairy",
   "metadata": {},
   "source": [
    "# Merge all the plates of all the combinations in one single dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89ca9d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N1Set89.xlsx\n",
      "N1Set89\n",
      "N2Set89.xlsx\n",
      "N2Set89\n",
      "N3Set89.xlsx\n",
      "N3Set89\n",
      "N4Set89.xlsx\n",
      "N4Set89\n",
      "N5Set89.xlsx\n",
      "N5Set89\n",
      "N6Set89.xlsx\n",
      "N6Set89\n",
      "N7Set89.xlsx\n",
      "N7Set89\n",
      "N8Set89.xlsx\n",
      "N8Set89\n"
     ]
    }
   ],
   "source": [
    "appended_data = []\n",
    "\n",
    "norm_features = \"/home/gauss/Desktop/Trained Features_FilteredBBox_pooledwellsd2d3d4/O8W_normalized/\"\n",
    "\n",
    "for feature_file in sorted(os.listdir(norm_features)):\n",
    "    print(feature_file)\n",
    "    norm_feature_data = pd.read_excel(os.path.join(norm_features, feature_file))\n",
    "    \n",
    "    #prefix_comb = feature_file.split(\"_\")[1]\n",
    "    prefix_comb = feature_file.split(\".\")[0]\n",
    "    print(prefix_comb)\n",
    "\n",
    "    if \"A81\" in prefix_comb:\n",
    "        combo = \"O3B\"\n",
    "        \n",
    "    elif \"A82\" in prefix_comb:\n",
    "        combo = 'KB'\n",
    "    \n",
    "    elif \"Set25\" in prefix_comb:\n",
    "        combo = 'KW'\n",
    "        \n",
    "    elif \"Set89\" in prefix_comb:\n",
    "        combo = 'O8W'\n",
    "        \n",
    "    elif \"863\" in prefix_comb:\n",
    "        combo = 'MHB'\n",
    "        \n",
    "    combination = combo\n",
    "    #print(combination)\n",
    "\n",
    "    norm_feature_data.insert(0,'Combination', combination)\n",
    "    \n",
    "    #prefix_plate = feature_file.split(\"_\")[1]\n",
    "    #prefix_plate = prefix_comb.split(\"_\")[1]\n",
    "    prefix_plate = list(prefix_comb)\n",
    "    #print(prefix_plate)\n",
    "\n",
    "    norm_feature_data.insert(0,'Plate number', prefix_plate[1] )\n",
    "\n",
    "    appended_data.append(norm_feature_data)\n",
    "    \n",
    "appended_data = pd.concat(appended_data)\n",
    "# write DataFrame to an excel sheet \n",
    "appended_data.to_excel('/home/gauss/Desktop/Trained Features_FilteredBBox_pooledwellsd2d3d4/O8W_normalized/alldata.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ddc911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the all data file and replace all null, -inf values by 0\n",
    "file_name = \"/home/gauss/Desktop/Trained Features_FilteredBBox_merged_plates/O3B_normalized/alldata.xlsx\"\n",
    "data = pd.read_excel(file_name)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cecedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Cancer_Count_left','Cancer_Count_right'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f1275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d235b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=data.fillna(0)\n",
    "df2.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('/home/gauss/Desktop/Pretrained Features/MHB_Features_Normalized/alldata.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6d6366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
